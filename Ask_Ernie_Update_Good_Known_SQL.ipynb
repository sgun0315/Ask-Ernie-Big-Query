{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNbbb06N4pMsY3ob/bv8m8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgun0315/Ask-Ernie-Big-Query/blob/main/Ask_Ernie_Update_Good_Known_SQL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QiFflLpBbWP5",
        "outputId": "18ba10cf-9ea8-4bdb-deb5-8b6f41a3a020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (2.24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (2025.4.26)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core) (0.6.1)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.11/dist-packages (3.32.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.4.26)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install google-api-core\n",
        "%pip install --upgrade google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "pdgkWvE-zkIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "project_id = \"syy-dom-np-fd67\"\n",
        "region = \"us-central1\"\n",
        "vertexai.init(project=project_id, location=region)"
      ],
      "metadata": {
        "id": "raPOEOOszo-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BQ_DATASET_NAME = \"scm_chatbot_datastore_dev\"\n",
        "BQ_KNOWLEDGE_DATASET_NAME = \"chatbot_knowledge_datastore_dev\"\n",
        "BQ_BUSINESS_KNOWLEDGE_TABLE_NAME = \"business_rules_v2\"\n",
        "\n",
        "APPLICATION_NAME = \"Merchandising\"\n",
        "GOOGLE_CLOUD_QUOTA_PROJECT = \"syy-dom-np-fd67\"\n",
        "GOOGLE_CLOUD_QUOTA_PROJECT_REGION = \"us-central1\"\n",
        "\n",
        "VECTOR_BUSINESS_RULES_MATCH_SCORE_MATCHES = 0.6"
      ],
      "metadata": {
        "id": "AEp-AD6XbaJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from typing import Literal\n",
        "\n",
        "from google.api_core.exceptions import GoogleAPICallError, BadRequest, ServiceUnavailable\n",
        "from google.cloud import bigquery\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class BQConnector:\n",
        "    \"\"\"Big Query Connector Implementation.\"\"\"\n",
        "\n",
        "    def __init__(self, source, project_id, region):\n",
        "        self.source = source\n",
        "\n",
        "        self.project_id = project_id\n",
        "        self.region = region\n",
        "        self.dataset_name = BQ_DATASET_NAME\n",
        "        self.chatbot_knowledge_dataset = BQ_KNOWLEDGE_DATASET_NAME\n",
        "\n",
        "        self._client = bigquery.Client(project=project_id, location=region)\n",
        "\n",
        "\n",
        "    def get_all_business_rules(self) -> list[dict]:\n",
        "      \"\"\"Fetch all business rules with their content.\"\"\"\n",
        "      table_name = BQ_BUSINESS_KNOWLEDGE_TABLE_NAME\n",
        "      full_table_path = f\"{self.project_id}.{self.chatbot_knowledge_dataset}.{table_name}\"\n",
        "\n",
        "      query = f\"\"\"\n",
        "          SELECT ruleset, content\n",
        "          FROM `{full_table_path}`\n",
        "          WHERE source_type = '{self.source}'\n",
        "      \"\"\"\n",
        "\n",
        "      try:\n",
        "          df = self.execute_query(query)\n",
        "          logger.info(\"✅ Retrieved %d business rules from table %s\", len(df), table_name)\n",
        "          return df.to_dict(orient=\"records\")\n",
        "      except Exception as e:\n",
        "          logger.error(\"❌ Failed to retrieve business rules: %s\", str(e), exc_info=True)\n",
        "          return []\n",
        "\n",
        "\n",
        "    def execute_query(self, query):\n",
        "        \"\"\"Execute the given query and return the result in dataframe\"\"\"\n",
        "        try:\n",
        "            return self._client.query_and_wait(query).to_dataframe()\n",
        "        except (TimeoutError, GoogleAPICallError, BadRequest, ServiceUnavailable) as e:\n",
        "            logger.error(\"Error Executing Query: %s\", e)\n",
        "            raise ResourceConnectionError(f\"Error executing query: {e}\", service=\"BigQuery\", errors=e) from e"
      ],
      "metadata": {
        "id": "9lQho-vxbgqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from typing import Optional, List, Literal\n",
        "\n",
        "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class EmbedderAgent:\n",
        "    \"\"\"Embedder Agent Implementation\"\"\"\n",
        "\n",
        "    agent_type: str = \"EmbedderAgent\"\n",
        "\n",
        "    def __init__(self, embeddings_model: str = \"text-embedding-004\"):\n",
        "        self.embeddings_model = embeddings_model\n",
        "        self.model = TextEmbeddingModel.from_pretrained(model_name=embeddings_model)\n",
        "        logger.info(\"Embedder Agent Initialized in the given project.\")\n",
        "\n",
        "    async def create(\n",
        "            self,\n",
        "            questions,\n",
        "            task: Literal[\"RETRIEVAL_QUERY\", \"RETRIEVAL_DOCUMENT\", \"SEMANTIC_SIMILARITY\"] = \"SEMANTIC_SIMILARITY\",\n",
        "            dimensionality: Optional[int] = 768,\n",
        "    ) -> List[List[float]]:\n",
        "        \"\"\"Text embedding with a Large Language Model.\"\"\"\n",
        "\n",
        "        inputs = [TextEmbeddingInput(text, task) for text in questions]\n",
        "        kwargs = {\"output_dimensionality\": dimensionality}\n",
        "        embeddings = await self.model.get_embeddings_async(inputs, **kwargs)\n",
        "        return [embedding.values for embedding in embeddings]"
      ],
      "metadata": {
        "id": "gefoXUbQe6iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "async def get_embeddings_for_text(text):\n",
        "    \"\"\"Get Text Embeddings from Model\"\"\"\n",
        "    embedder = EmbedderAgent(embeddings_model='text-embedding-004')\n",
        "    embeddings = await embedder.create([text])\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "jAJHrIG5fe2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bq_connector = BQConnector(\n",
        "    APPLICATION_NAME,\n",
        "    GOOGLE_CLOUD_QUOTA_PROJECT,\n",
        "    GOOGLE_CLOUD_QUOTA_PROJECT_REGION\n",
        ")"
      ],
      "metadata": {
        "id": "ov_ycpYNqYAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "rules_df = pd.DataFrame(\n",
        "    {\n",
        "        \"ruleset\": [\n",
        "            \"purchase order primary status should be 'OPEN' and purchase order secondary status should be 'ACCEPTED' and purchase order type should be 'REGULAR' and vendor id should not be equals to '359958' or '495149'. no need to consider about order control number or scheduled purchase order receipt timestamp\",\n",
        "            \"(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED'\",\n",
        "            \"date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED'\",\n",
        "            \"order control number is null and purchase order primary status should be 'OPEN'\",\n",
        "            \"anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\",\n",
        "            \"purchase order primary status should be 'RECOMMENDED' and purchase order secondary status should be 'RECOMMENDED' and replenishment system should be 'DPR'\",\n",
        "            \"purchase order primary status should be 'CLOSED'. If {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value\",\n",
        "            \"purchase order primary status should be 'CLOSED'. If the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic\"\n",
        "        ],\n",
        "        \"content\": [\n",
        "            \"Unscheduled PO or Unscheduled Purchase Order\",\n",
        "            \"Purchase Orders or POs older than given month\",\n",
        "            \"Purchase Order or PO with past scheduled appointment\",\n",
        "            \"Purchase Order or PO without Order Control Number | Invalid PO | POs for cleanup\",\n",
        "            \"Late PO or Late Purchase Order\",\n",
        "            \"PO or Purchase Order with 'RECOMMENDED' status\",\n",
        "            \"Purchase Order or POs with over of total quantity | overage POs\",\n",
        "            \"Purchase Order or POs with short of total quantity. | shortage PO's.\"\n",
        "        ],\n",
        "        \"source_type\": [\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME,\n",
        "            APPLICATION_NAME\n",
        "        ],\n",
        "        \"app\": [\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\",\n",
        "            \"SIM360\"\n",
        "        ]\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "T_dyRSKMW3UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "\n",
        "async def generate_and_upload_business_rule_embeddings():\n",
        "    # Step 2: Generate embeddings\n",
        "    embeddings = await asyncio.gather(*[get_embeddings_for_text(text) for text in rules_df[\"content\"]])\n",
        "    rules_df[\"embedding\"] = [list(map(float, emb)) for emb in embeddings]  # Convert to list[float]\n",
        "\n",
        "    # Step 3: Prepare rows\n",
        "    records = []\n",
        "    for _, row in rules_df.iterrows():\n",
        "        records.append({\n",
        "            \"ruleset\": row[\"ruleset\"],\n",
        "            \"content\": row[\"content\"],\n",
        "            \"embedding\": row[\"embedding\"],\n",
        "            \"source_type\": row[\"source_type\"],\n",
        "            \"app\": row[\"app\"],\n",
        "        })\n",
        "\n",
        "    # Step 4: Upload to BigQuery\n",
        "    table_path = f\"{GOOGLE_CLOUD_QUOTA_PROJECT}.{BQ_KNOWLEDGE_DATASET_NAME}.{BQ_BUSINESS_KNOWLEDGE_TABLE_NAME}\"\n",
        "    errors = bq_connector._client.insert_rows_json(table_path, records)\n",
        "\n",
        "\n",
        "    if errors:\n",
        "        print(\"❌ Failed to insert rows:\", errors)\n",
        "    else:\n",
        "        print(\"✅ Business rule embeddings uploaded successfully!\")\n"
      ],
      "metadata": {
        "id": "ofAeID5eye-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await generate_and_upload_business_rule_embeddings()"
      ],
      "metadata": {
        "id": "571SsP27Unk4",
        "outputId": "c95f0e3b-7ab5-4e96-cf7a-9c47d7fb28cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Business rule embeddings uploaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bq_connector.get_all_business_rules()"
      ],
      "metadata": {
        "id": "Cha_EHpMUw4p",
        "outputId": "d2ccbc2b-e856-4b59-e6bb-1859ed034f14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ruleset': \"purchase order primary status should be 'OPEN' and purchase order secondary status should be 'ACCEPTED' and purchase order type should be 'REGULAR' and vendor id should not be equals to '359958' or '495149'. no need to consider about order control number or scheduled purchase order receipt timestamp\",\n",
              "  'content': 'Unscheduled PO or Unscheduled Purchase Order'},\n",
              " {'ruleset': \"(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED'\",\n",
              "  'content': 'Purchase Orders or POs older than given month'},\n",
              " {'ruleset': \"date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED'\",\n",
              "  'content': 'Purchase Order or PO with past scheduled appointment'},\n",
              " {'ruleset': \"order control number is null and purchase order primary status should be 'OPEN'\",\n",
              "  'content': 'Purchase Order or PO without Order Control Number | Invalid PO | POs for cleanup'},\n",
              " {'ruleset': \"anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\",\n",
              "  'content': 'Late PO or Late Purchase Order'},\n",
              " {'ruleset': \"purchase order primary status should be 'RECOMMENDED' and purchase order secondary status should be 'RECOMMENDED' and replenishment system should be 'DPR'\",\n",
              "  'content': \"PO or Purchase Order with 'RECOMMENDED' status\"},\n",
              " {'ruleset': \"purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value\",\n",
              "  'content': 'Purchase Order or POs with over of total quantity | overage POs'},\n",
              " {'ruleset': \"purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic\",\n",
              "  'content': \"Purchase Order or POs with short of total quantity. | shortage PO's.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iBi-FNXkIVh1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}